{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f83b3f4-16e0-4419-8dd9-4aa8611bcaf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Michelin Restaurant Dataset: Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d6ccfcf-189a-4d7e-847b-a8073cad3cf3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The dataset comes from [Kaggle](https://www.kaggle.com/datasets/ngshiheng/michelin-guide-restaurants-2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8971ed1-3894-4b8d-b8c9-b2b6e8bc8d11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cd14fdd-baeb-4fcf-86f4-a469eb4389ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Catalog, Schema Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0900a1ed-ed9d-4e43-82ca-e5680c982f19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_ = os.getenv('CATALOG_NAME')\n",
    "schema_ = os.getenv('SCHEMA_NAME')\n",
    "data_path_ = os.getenv('DATA_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b1632b2-34eb-43a3-b332-5e129a2e80cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS \"+catalog_)\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS \"+catalog_+\".\"+schema_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6fcbe52-e74b-4fad-bf7e-593e253c3425",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG \"+catalog_)\n",
    "spark.sql(\"USE SCHEMA \"+schema_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b07fbe8-2f88-4633-8efa-c0c4c41969af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data Ingestion from Volume [Bronze]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1af8f98c-8533-4ee7-b081-4e187761fd83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "There is a problem in the csv file, especially on \"\", \"\"\" or \"\"\"\" followed by a comma within string descriptions, which results in a string trucation.\n",
    "\n",
    "There are however empty fields denoted by ,\"\", (in one instance this is followed by a new line character instead of a comma, i.e. restaurant name Goosefoot), so a direct replacement cannot work.\n",
    "\n",
    "The idea is to perform these steps:\n",
    "- Replace ,\"\", with < (non existent char in the whole file)\n",
    "- Replace \"\"\"\" with ' as they are all inside quotated fields (\"\"\"\", doesn't exist)\n",
    "- Replace \"\"\"(+new line) with \"(+new line)\n",
    "- Replace ,\"\"\" with ,\"\n",
    "- Replace \"\"\", with '\", (7 instances)\n",
    "- Handle remaining \"\"\" manually (2 instances)\n",
    "- Replace \"\" with '\n",
    "- Restore, by replacing < with ,\"\", (handle the one instance above manually)\n",
    "- Handle Goosefoot restaurant line separator manually\n",
    "\n",
    "After that, the descriptions should be cleaned up and the shortest one is 36 chars, which is also in the original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43c056d7-38f0-421d-b9cd-f0eb594aa16d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Download the file to a volume\n",
    "import urllib\n",
    "\n",
    "\"\"\"\n",
    "volume_ = catalog_+'.'+schema_+'.init'\n",
    "spark.sql(\"CREATE VOLUME IF NOT EXISTS \"+volume_)\n",
    "urllib.request.urlretrieve(\n",
    "  data_path_,\n",
    "  \"/Volumes/\"+catalog_+\"/\"+schema_+\"/init/michelin_data.csv\")\n",
    "\"\"\"\n",
    "filepath_ = f\"dbfs:/Volumes/\"+catalog_+\"/\"+schema_+\"/init/michelin_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6537957e-6e8b-4f0d-ba2f-a9e9fd9a83c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_ = (spark.\n",
    "           read.\n",
    "           option(\"header\", True).\n",
    "           option(\"delimiter\", \",\").\n",
    "           option(\"encoding\", \"utf-8\").\n",
    "           option(\"quotechar\", '\"').\n",
    "           option(\"doublequote\", False).\n",
    "           format(\"csv\").\n",
    "           load(filepath_).\n",
    "           createOrReplaceTempView(\"bronze_v\"))\n",
    "\n",
    "display(spark.sql(\"SELECT * FROM bronze_v LIMIT 10;\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a01ae57d-8f48-4cff-905e-2e5d508b032b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS bronze_data;\n",
    "CREATE TABLE bronze_data AS\n",
    "  select * from bronze_v;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41636d99-320a-4297-beb6-a48ba022197f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afdeba98-94af-4d59-87b0-25ae31238801",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_df = spark.sql(\"SELECT * FROM bronze_data\")\n",
    "display(dbutils.data.summarize(bronze_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7f4fa54-dbbd-4b7b-bcb8-b13f8523ac37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- -- -- Price\n",
    "select Price, len(Price)::int price_score, count(*) from bronze_data group by 1,2 order by 1,2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f9f2059-682c-4a66-91a9-6e8c6df26d92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from bronze_data where Price is null;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72be4417-e439-4830-a0d2-3390dfe299f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- -- -- Award\n",
    "select Award, \n",
    "  case Award\n",
    "  when '1 Star' then 1\n",
    "  when '2 Stars' then 2\n",
    "  when '3 Stars' then 3\n",
    "  when 'Bib Gourmand' then 0.5\n",
    "  when 'Selected Restaurants' then 0.25\n",
    "  end as Stars_score\n",
    "  ,count(*)\n",
    "  from bronze_data group by 1,2 order by 1,2;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d0e16a1-62ad-4ec1-8905-e9d75a603141",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- -- -- Quality Ratio\n",
    "with d0 as (\n",
    "  select *\n",
    "    ,case Award\n",
    "      when '1 Star' then 1\n",
    "      when '2 Stars' then 2\n",
    "      when '3 Stars' then 3\n",
    "      when 'Bib Gourmand' then 0.5\n",
    "      when 'Selected Restaurants' then 0.25\n",
    "      end as Stars_score\n",
    "  from bronze_data\n",
    ")\n",
    "select \n",
    "  Stars_score\n",
    "  ,len(Price)::float Price_score\n",
    "  ,Stars_score / len(Price)::float as Quality\n",
    "  , count(*) recs\n",
    "from d0\n",
    "where Price is not null\n",
    "group by 1,2,3 order by 1,2,3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d80fefb5-3754-4666-8cd7-a86946058c37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- -- -- Cuisine\n",
    "select cuisine, count(*) from bronze_data group by 1 order by 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "776f3c00-17ec-4d05-be45-53d3cfdaba76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- -- -- Split the cuisine as some values are comma separated\n",
    "with d0 as (\n",
    "  select\n",
    "    trim(case when cuisine not like '%,%' then cuisine else split_part(cuisine, ',', 1) end) as Cuisine_l1,\n",
    "    trim(case when cuisine not like '%,%' then cuisine else split_part(cuisine, ',', 2) end) Cuisine_l2,\n",
    "    name\n",
    "    from bronze_data\n",
    ")\n",
    "    select Cuisine_l1, count(*) recs\n",
    "    from d0\n",
    "    group by 1 order by 2 desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23442f49-6174-4e58-92dd-44b7e896e17e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from bronze_data where cuisine = \"'\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f693e8fc-575b-41cd-a834-c57977b9e0f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- -- -- Location\n",
    "select location,\n",
    "  trim(case when location not like '%,%' then location else split_part(location, ',', 1) end) as City,\n",
    "  trim(case when location not like '%,%' then location else split_part(location, ',', 2) end) Country,\n",
    " count(*) as recs_\n",
    "from bronze_data\n",
    "group by 1,2,3 order by 3,1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7019aa6-a612-46c5-8521-d38077a62cd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- -- -- Country\n",
    "with d0 as (\n",
    "  select *\n",
    "  ,trim(case when location not like '%,%' then location else split_part(location, ',', 1) end) as City\n",
    "  ,trim(case when location not like '%,%' then location else split_part(location, ',', 2) end) as Country\n",
    "  from bronze_data\n",
    ")\n",
    "  select country, count(*) recs_\n",
    "  from d0\n",
    "  group by 1 order by 2 desc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ab40f3e-a66b-4db0-bd6b-807785cfd372",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**`Note about Countries`**: To be recognized by maps, we should make sure these adhere to the ISO3 standard country names.\n",
    "\n",
    "The names can be found from the gapminder dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d8e9c56-fba1-43ae-ba92-b9ff8067e3c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Iso3 Countries\n",
    "import plotly.express as px\n",
    "df = px.data.gapminder()\n",
    "iso3_codes = df['iso_alpha'].unique()\n",
    "country_names = df['country'].unique()\n",
    "\n",
    "# Current countries\n",
    "countries__ = spark.sql(\"\"\"\n",
    "                        with d0 as (\n",
    "                            select *\n",
    "                            ,trim(case when location not like '%,%' then location else split_part(location, ',', 1) end) as City\n",
    "                            ,trim(case when location not like '%,%' then location else split_part(location, ',', 2) end) as Country\n",
    "                            from bronze_data\n",
    "                          )\n",
    "                            select distinct\n",
    "                              case when country = 'Hong Kong' or country = 'Hong Kong SAR China' then 'Hong Kong, China'\n",
    "                                when country = 'Czechia' then 'Czech Republic'\n",
    "                                when country = 'Türkiye' then 'Turkey'\n",
    "                                when country = 'USA' then 'United States'\n",
    "                                when country = 'China Mainland' then 'China'\n",
    "                                when country = 'Dubai' or country = 'Abu Dhabi' then 'United Arab Emirates'\n",
    "                                else country end as country\n",
    "                            from d0;\n",
    "                        \"\"\").toPandas()\n",
    "countries_ = countries__['country'].to_list()\n",
    "\n",
    "countries_to_fix = [c for c in countries_ if c not in country_names]\n",
    "print(\":: Here a list of countries that wouldn't get recognized:\")\n",
    "print(countries_to_fix)\n",
    "\n",
    "print(country_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db21f66f-8caa-4212-9b98-36c7ceee0790",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- -- -- Description\n",
    "select len(Description), count(*) from bronze_data group by 1 order by 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44213ba7-8f46-4338-9f83-55395fddd5d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select name, len(description), description from bronze_data where len(description) < 100\n",
    "order by 2 asc; -- There are some descriptions that include nested \"\", therefore they get imported in a wrong way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e66e0265-b22c-4a04-8183-35ca89ff321e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from bronze_data where Name = 'Heng Gi Goose and Duck Rice';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d72705c0-a569-4c31-b981-5306525ba4e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data Cleaning [Silver]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6608e236-8ae9-437d-8d76-fdbe943bc042",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS silver_data;\n",
    "CREATE TABLE silver_data AS\n",
    "with d0 as (\n",
    "  select \n",
    "    concat('res-id-', cast(100000+row_number() over(order by Longitude::float, Latitude::float, `Location`, `Name`) as string)) Res_ID,\n",
    "    `Name`, Address, `Location`,\n",
    "    trim(case when location not like '%,%' then `Location` else split_part(location, ',', 1) end) as City,\n",
    "    trim(case when location not like '%,%' then `Location` else split_part(location, ',', 2) end) Country_,\n",
    "    Longitude::float, Latitude::float, PhoneNumber, `Url` as MichelineUrl, WebsiteUrl,\n",
    "    Cuisine, \n",
    "    trim(case when cuisine not like '%,%' then cuisine else split_part(cuisine, ',', 1) end) as Cuisine_l1,\n",
    "    trim(case when cuisine not like '%,%' then cuisine else split_part(cuisine, ',', 2) end) Cuisine_l2,\n",
    "    Price, len(Price)::int Price_score,\n",
    "    Award,\n",
    "    case Award\n",
    "      when '1 Star' then 1\n",
    "      when '2 Stars' then 2\n",
    "      when '3 Stars' then 3\n",
    "      when 'Bib Gourmand' then 0.5\n",
    "      when 'Selected Restaurants' then 0.25\n",
    "      end as Stars_score,\n",
    "    GreenStar::int,\n",
    "    FacilitiesAndServices, Description\n",
    "  from bronze_data\n",
    "  where \n",
    "    Price is not null -- Removing one Japanese restaurant\n",
    "), d1 as (\n",
    "  select *,\n",
    "    case when Country_ = 'Hong Kong' or Country_ = 'Hong Kong SAR China' then 'Hong Kong, China'\n",
    "        when Country_ = 'Czechia' then 'Czech Republic'\n",
    "        when Country_ = 'Türkiye' then 'Turkey'\n",
    "        when Country_ = 'USA' then 'United States'\n",
    "        when Country_ = 'China Mainland' then 'China'\n",
    "        when Country_ = 'Dubai' or Country_ = 'Abu Dhabi' then 'United Arab Emirates'\n",
    "        else Country_ end\n",
    "    as Country,\n",
    "    Stars_score / Price_score::float as Quality_ratio\n",
    "    from d0\n",
    ")\n",
    "select * EXCEPT(Country_)\n",
    "from d1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4306506f-35f8-43de-87f3-a78f118587d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_df = spark.sql(\"SELECT * FROM silver_data\")\n",
    "display(silver_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dffb3c00-6341-4eed-9b04-687e941eaba7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Export Silver Data to Parquet\n",
    "vol_ = \"/Volumes/michelin_ga/restaurants/init/silver_data.parquet\"\n",
    "(silver_df\n",
    "      .write\n",
    "      .format(\"parquet\")\n",
    "      .mode(\"overwrite\")\n",
    "      .save(vol_))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4320825364105492,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "01_Michelin_DataPreparation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
