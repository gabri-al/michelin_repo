{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f83b3f4-16e0-4419-8dd9-4aa8611bcaf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Michelin Restaurant Dataset: ImgGeneration (Shutterstock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e56d506-627d-4524-860d-87f131a39087",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Text-to-img models:\n",
    "- Shutterstock: endpoint already up and running on Databricks but it is not compatible with the resolution parameter to lower it\n",
    "- stable-diffusion-2-1: available on [Huggingface](https://huggingface.co/stabilityai/stable-diffusion-2-1) and it is mentioned in this [doc](https://docs.google.com/document/d/1GFZzo8paONRC9YYM-nwu1z1DXEqyOqh5ziiSe9kS06Q/edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8971ed1-3894-4b8d-b8c9-b2b6e8bc8d11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import requests\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cd14fdd-baeb-4fcf-86f4-a469eb4389ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Catalog, Schema Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0900a1ed-ed9d-4e43-82ca-e5680c982f19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_ = os.getenv('CATALOG_NAME')\n",
    "schema_ = os.getenv('SCHEMA_NAME')\n",
    "spark.sql(\"USE CATALOG \"+catalog_)\n",
    "spark.sql(\"USE SCHEMA \"+schema_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65b9ffdb-97fe-434a-b5e9-60e1aa7e64e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Check if secret scope is set up to reach endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eff0a21-f08d-41a2-9f5b-483b201de752",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scope_name_ = 'michelin_scope'\n",
    "secret_name_ = 'pat_ga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78a796dd-aefc-4b8f-961e-a6788024956e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check scope\n",
    "existing_scopes = [scope.name for scope in dbutils.secrets.listScopes()]\n",
    "if scope_name_ in existing_scopes:\n",
    "    print(\"Secret scope exists!\")\n",
    "else:\n",
    "    print(\"Secret scope doesn't exist, create it via CLI!\")\n",
    "\n",
    "# Check secret\n",
    "existing_secrets = [secret.key for secret in dbutils.secrets.list(scope_name_)]\n",
    "if secret_name_ in existing_secrets:\n",
    "    print(\"Secret exists!\")\n",
    "else:\n",
    "    print(\"Secret doesn't exist, create it via CLI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b07fbe8-2f88-4633-8efa-c0c4c41969af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Read Silver Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8636e0c-8024-441d-ba15-4598bfad75d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_df = spark.sql(\"SELECT * FROM silver_data\")\n",
    "display(silver_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6aca511-337f-4f2c-ae2e-c19ee7f58425",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Testing Image Generation for 1 record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96cf6f44-24da-4289-affd-6d5cec447171",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "endpoint_url_ = 'https://e2-demo-field-eng.cloud.databricks.com/serving-endpoints/databricks-shutterstock-imageai/invocations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6900b8ae-8a1c-48f4-9a1f-78d98def3dfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_df = (spark.\n",
    "  read.\n",
    "  table(catalog_+'.'+schema_+'.silver_data').\n",
    "  select(['Res_ID', 'Name', 'Description']).\n",
    "  where(\"Res_ID = 'res-id-100092'\"))\n",
    "  \n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb26176-26ed-4145-98a7-3d563594df01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate an text-to-image request\n",
    "def generateImg(row_, endpoint_url = endpoint_url_):\n",
    "\n",
    "  ## Extract info from the row\n",
    "  id_ = row_['Res_ID']\n",
    "  name_ = row_['Name']\n",
    "  text_ = row_['Description']\n",
    "  text_pyload = {\n",
    "    \"prompt\": text_\n",
    "  }\n",
    "\n",
    "  ## Reach endpoint and process response\n",
    "  headers = {\n",
    "    \"Authorization\": f\"Bearer \" + dbutils.secrets.get(scope=scope_name_, key=secret_name_)\n",
    "  }\n",
    "\n",
    "  response = requests.post(endpoint_url, json=text_pyload, headers=headers)\n",
    "  if response.status_code == 200:\n",
    "    image_data = response.json()['data'][0]['b64_json']\n",
    "    print(\"%s :: Successful!\" % id_)\n",
    "  else:\n",
    "    image_data = None\n",
    "    print(\"%s :: Failed! Status code: %s\" % (id_, response.status_code))\n",
    "\n",
    "  return {\n",
    "    'Res_ID': id_,\n",
    "    'Img': image_data\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dc4ce23-e285-44ea-819a-669c30fff3b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Call endpoint\n",
    "img_response = generateImg(test_df.limit(1).collect()[0])\n",
    "print(test_df.limit(1).collect()[0])\n",
    "\n",
    "# Extract output\n",
    "if img_response['Img'] is not None:\n",
    "  print(img_response['Img']) ## This will be stored in the dataset\n",
    "  # Display img\n",
    "  image = io.BytesIO(base64.decodebytes(bytes(img_response['Img'], \"utf-8\")))\n",
    "  decoded_img = Image.open(image)\n",
    "  resized_img = decoded_img.resize((300, 300))\n",
    "  display(resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf02b5a5-79ce-44a9-888a-7d75ea0c5177",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Write the img string into file\n",
    "directory = \"/Volumes/\"+catalog_+\"/\"+schema_+\"/init\"\n",
    "file_path = directory + \"/\" + img_response['Res_ID']\n",
    "\n",
    "with open(file_path, 'w') as file: # write img as string\n",
    "  file.write(img_response['Img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52dbf2b4-c59c-450e-9756-b318b6e299c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Applying img generation at scale with Pandas UDFs on Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21fc3c2e-3269-47af-a4a9-f7f7c049a3d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Notes:\n",
    "- Within a spark UDF we cannot use `dbutils` (source [here](https://docs.databricks.com/en/dev-tools/databricks-utils.html#databricks-utilities)). Therefore, we should define the PAT as a global variable outside the function and then use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbc99b8d-f0c1-481d-a0ed-11010a5fc175",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Save PAT as global variable\n",
    "PAT_ = dbutils.secrets.get(scope=scope_name_, key=secret_name_)\n",
    "\n",
    "## Create the base function\n",
    "def generateImg(text_, endpoint_url = endpoint_url_):\n",
    "  ## Convert text into prompt format\n",
    "  text_pyload = {\n",
    "    \"prompt\": text_\n",
    "    #\"resolution\": \"256x256\" ## Lowering img resolution (default 1024x1024) -- not supported by the endpoint\n",
    "  }\n",
    "  ## Reach endpoint\n",
    "  headers = {\n",
    "    \"Authorization\": f\"Bearer \" + PAT_\n",
    "  }\n",
    "  response = requests.post(endpoint_url, json=text_pyload, headers=headers)\n",
    "  ## Process response\n",
    "  if response.status_code == 200:\n",
    "    image_data = response.json()['data'][0]['b64_json']\n",
    "  else:\n",
    "    image_data = None\n",
    "    print(\"Failed! Status code: %s\" % (response.status_code))\n",
    "  return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb6e64f1-ae37-49fe-9f49-bbbf3bca9ec5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Encapsulate function into a PandasUDF\n",
    "@pandas_udf(\"string\")\n",
    "def save_Imgs(res_descr_: pd.Series) -> pd.Series:\n",
    "  return res_descr_.apply(generateImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "733e111e-adff-4153-aad4-177978fecf29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create an empty table for imgs\n",
    "DROP TABLE IF EXISTS rest_descr_img_genai;\n",
    "CREATE TABLE IF NOT EXISTS rest_descr_img_genai (\n",
    "  Res_ID STRING,\n",
    "  `Name` String,\n",
    "  GenAI_Img String\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e920c327-9753-4bf5-932a-e9d921346f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Generating Img for all entries requires lot of compute and memory -- Generate only for some records\n",
    "(spark.table(catalog_+'.'+schema_+'.silver_data')      \n",
    "      .filter(col(\"Stars_score\") >= 1)\n",
    "      .filter(col(\"Country\").isin('USA', 'Italy'))\n",
    "      .select(['Res_ID', 'Name', 'Description'])\n",
    "      .withColumn('GenAI_Img', save_Imgs('Description'))\n",
    "      .drop('Description')\n",
    "      .write\n",
    "      .mode('overwrite')\n",
    "      .saveAsTable('rest_descr_img_genai'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3a58e38-3997-4d32-8dab-1867b9a09bfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1284968239718118,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02a_Michelin_ImgGen_Shutterstock",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
